{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2e0e6c",
   "metadata": {},
   "source": [
    "# Large Language Model Serving Tutorial with DigitalHub\n",
    "\n",
    "This notebook demonstrates how to deploy and serve a pre-trained Large Language Model using KubeAI with the DigitalHub SDK. We'll work with LLama model for text generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b079a02d",
   "metadata": {},
   "source": [
    "## Project Initialization\n",
    "\n",
    "Initialize a DigitalHub project using consistent naming with other tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "import getpass as gt\n",
    "\n",
    "USERNAME = gt.getuser()\n",
    "\n",
    "project = dh.get_or_create_project(f\"{USERNAME}-tutorial-project\")\n",
    "print(project.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493dc86",
   "metadata": {},
   "source": [
    "## Step 1: Model Configuration\n",
    "\n",
    "We'll create a function to serve the LLama3.2 model directly from HuggingFace Hub.\n",
    "The model path uses the `hf://` protocol to directly reference models from the HuggingFace Hub without manual downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a6b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_function = project.new_function(\n",
    "    name=\"llama32-1b\",\n",
    "    kind=\"kubeai-text\",\n",
    "    model_name=f\"{USERNAME}-model\",\n",
    "    url=\"ollama://llama3.2:1b\",\n",
    "    engine='OLlama',\n",
    "    features=['TextGeneration']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda90a8",
   "metadata": {},
   "source": [
    "## Step 2: Model Serving\n",
    "\n",
    "Now we'll deploy our LLM model. We're using a GPU profile (`1xa100`) to accelerate the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_run = llm_function.run(\"serve\", profile=\"1xa100\", wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a3e7d5",
   "metadata": {},
   "source": [
    "Let's check that our service is running and ready to accept requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = llm_run.refresh().status.service\n",
    "print(\"Service status:\", service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b995b72-e1a9-4532-9fe7-b37bf8a5dd2d",
   "metadata": {},
   "source": [
    "When the service is ready, we need to wait for the model to be downloaded and deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a51ed1a-470c-4291-b1e6-9b5129bac764",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = llm_run.refresh().status.k8s.get(\"Model\")['status']\n",
    "print(\"Model status:\", status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f418f",
   "metadata": {},
   "source": [
    "We can check the logs for the main container if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "log = base64.b64decode(llm_run.refresh().logs()[0][\"content\"]).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337f341",
   "metadata": {},
   "source": [
    "### Test the LLM API\n",
    "\n",
    "Now let's test our deployed model with a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =llm_run.refresh().status.k8s.get(\"Model\").get(\"metadata\").get(\"name\")\n",
    "json_payload = {'model': model_name, 'prompt': 'how can i use a PAT with the DigitalHub?'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b38bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "url = service['url']+'/v1/completions'\n",
    "\n",
    "r = requests.post(url, json=json_payload)\n",
    "print(f\"Status Code: {r.status_code}\")\n",
    "pp.pprint(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389e78c",
   "metadata": {},
   "source": [
    "The SDK exposes an helper method for invoking the service, eliminating the need for custom HTTP request handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "r = llm_run.invoke(json=json_payload, url=service['url']+'/v1/completions').json()\n",
    "pp.pprint(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614da78",
   "metadata": {},
   "source": [
    "### Understanding the Results\n",
    "\n",
    "The model returns a text with the completition of the prompt, along with usage information which can be used for monitoring or billing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a0b05",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* check that the model is usable via OpenWebUI\n",
    "* check logs and metrics from the console\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad644834-13f8-4fad-a630-91331e6e925a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
