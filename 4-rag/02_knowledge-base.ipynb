{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b0685c-b165-4475-93d5-8d3e45bc5fbd",
   "metadata": {},
   "source": [
    "# Building a Knowledge base \n",
    "\n",
    "The notebook will guide the user into building a knowledge base with the DigitalHub.\n",
    "\n",
    "Features:\n",
    "\n",
    "* text extraction from PDF\n",
    "* embedding generation\n",
    "* vectore store support\n",
    "* automation via triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==1.109.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab9e55-4d84-4cdc-b3b9-9a7e4c5a9296",
   "metadata": {},
   "source": [
    "## Project Initialization\n",
    "\n",
    "Initialize a DigitalHub project using consistent naming with other tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2cb2e-a974-43eb-9ad7-da8e23127057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "import getpass as gt\n",
    "\n",
    "USERNAME = gt.getuser()\n",
    "\n",
    "project = dh.get_or_create_project(f\"{USERNAME}-tutorial-project\")\n",
    "print(project.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527ca4e-1859-430c-bbec-ea27d6b1303a",
   "metadata": {},
   "source": [
    "# Step 1: Deploy a text extraction service\n",
    "\n",
    "We will deploy a service (API) able to recieve a PDF file and return the text, along with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bbfb0-bd90-4bcc-a79f-845fdd15e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tika_function = project.new_function(\"tika\", kind=\"container\", image=\"apache/tika:latest-full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56c64a-8140-4423-b3f3-5f0bfdbb1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tika_run = tika_function.run(\"serve\", service_ports = [{\"port\": 9998, \"target_port\": 9998}], wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a09fb-b80f-4f00-a094-35e3866ba49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = tika_run.refresh().status.service\n",
    "print(\"Service status:\", service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d8505-5059-47c7-b389-3b7ac3c48e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIKA_URL = tika_run.status.to_dict()[\"service\"][\"url\"]\n",
    "print(TIKA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05200888-e6c0-48ab-b3b8-b4fb76080a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tika_run.invoke(url=\"http://\"+TIKA_URL)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a322c6-cc25-4dad-90bb-df68bbfbfec2",
   "metadata": {},
   "source": [
    "### Text extraction\n",
    "Now we need to define a python function which will read an artifact from the platform repository and leverage the Tika service to extract the textual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d24971-8fa8-45cf-ba9b-e68ba8d9893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_function = project.new_function(\n",
    "    name=\"extract\",\n",
    "    kind=\"python\",\n",
    "    python_version=\"PYTHON3_10\",\n",
    "    code_src=\"src/extract.py\",\n",
    "    handler=\"extract_text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b4bbf-7575-47b4-91f3-23c3e071d086",
   "metadata": {},
   "source": [
    "Let's test the function with a sample pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53100f2-b2af-4a46-be41-3303319f29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = project.log_artifact(\"pat.pdf\",kind=\"artifact\", source=\"docs/digitalhub-docs-pat.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5d839-a745-40c0-ae1a-966de074c203",
   "metadata": {},
   "source": [
    "We'll pass the artifact to the function execution, along with tika service url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef921b07-4e8c-41fc-b214-1fe3d6a07e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_run = extract_function.run(\"job\", inputs={\"artifact\": pdf.key}, parameters={\"tika_url\": TIKA_URL}, wait=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204cb13a-2d9a-4ca8-8b2b-cc5eb33e5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_run.status.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b0dda0-960d-436d-b64e-e9b66555fec9",
   "metadata": {},
   "source": [
    "Let's read the file and check the content is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9074c-b607-4940-9cca-36d2bbf76030",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_artifact = project.get_artifact(\"pat.pdf_output.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05f5da3-acbf-44f1-8949-5b296379d2f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html_file = html_artifact.download(overwrite=True)\n",
    "with open(html_file, 'r') as file:\n",
    "    file_content = file.read()\n",
    "    print(file_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187d621-70ea-41d5-93a8-1bf9d4c07ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61860e93-4a9c-457e-a6d0-b2d82c6be907",
   "metadata": {},
   "source": [
    "# Step 2: Embeddings\n",
    "\n",
    "To generate embeddings from the text extracted from documents we need to first deploy a suitable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388a444-58c8-4c67-b895-dc2f5448d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_function = project.new_function(\n",
    "    \"embed\",\n",
    "    kind=\"kubeai-text\",\n",
    "    model_name=\"model\",\n",
    "    features=[\"TextEmbedding\"],\n",
    "    engine=\"OLlama\",\n",
    "    url=\"ollama://nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e29a58-72c5-4024-a7fa-0da5b9f61089",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_run = embed_function.run(\"serve\", wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a1c61-96c2-4626-af17-23466e0ac74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = embed_run.refresh().status\n",
    "print(\"Service status:\", status.state)\n",
    "status =embed_run.status.k8s.get(\"Model\")['status']\n",
    "print(\"Model status:\", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e797d-2b19-4c59-a0e8-6b212025f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_URL = embed_run.status.to_dict()[\"service\"][\"url\"]\n",
    "EMBED_MODEL = embed_run.status.to_dict()[\"openai\"][\"model\"]\n",
    "print(f\"service {EMBED_URL} with model {EMBED_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f7661-a6e3-4da9-beca-55ecdcfc8b42",
   "metadata": {},
   "source": [
    "Let's check that the model is ready. We need the OpenAI client installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512d7cd-2176-4674-8ee4-074d3bf4a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"ignored\", base_url=f\"{EMBED_URL}/v1\")\n",
    "response = client.embeddings.create(\n",
    "    input=\"Some example text.\",\n",
    "    model=EMBED_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3973e0-c26f-4286-9a4e-17862a90ca29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207122db-54df-4fb2-a690-74cc14697dfb",
   "metadata": {},
   "source": [
    "## Embedding generation\n",
    "\n",
    "Now we need to define a function to read the text from the repository and push the data into the vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda14ec6-f206-4299-8bc8-f46c315aa47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_function = project.new_function(\n",
    "    name=\"embedder\",\n",
    "    kind=\"python\",\n",
    "    python_version=\"PYTHON3_10\",\n",
    "    image=\"harbor.digitalhub.smartcommunitylab.it/dslab/dslab-platform-harbor.atlas.fbk.eu/dslab/dslab-platform-msaloni-tutorial-project-rag-service:994e5\",\n",
    "    requirements=[\n",
    "        \"transformers==4.50.3\",\n",
    "        \"psycopg_binary\",\n",
    "        \"openai\",\n",
    "        \"langchain-text-splitters\",\n",
    "        \"langchain-community\",\n",
    "        \"langgraph\",\n",
    "        \"langchain-core\",\n",
    "        \"langchain-huggingface\",\n",
    "        \"langchain_postgres\",\n",
    "        \"langchain[openai]\",\n",
    "        \"beautifulsoup4\",\n",
    "    ],\n",
    "    code_src=\"src/embedder.py\",\n",
    "    handler=\"process\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7ac3b-27be-4f4f-b309-7dc7b2f61131",
   "metadata": {},
   "source": [
    "Let's put the various pieces together:\n",
    "1. Embed model is served at EMBED_URL with EMBED_MODEL\n",
    "2. Input artifact (html) is html_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb703b-4f09-4a7f-8557-5246ce3b46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_run = embedder_function.run(\n",
    "    \"job\",\n",
    "    inputs={\"input\": html_artifact.key},\n",
    "    envs=[\n",
    "        {\n",
    "            \"name\": \"EMBEDDING_SERVICE_URL\",\n",
    "            \"value\": EMBED_URL\n",
    "        },\n",
    "        {    \"name\": \"EMBEDDING_MODEL_NAME\",\n",
    "            \"value\": EMBED_MODEL,\n",
    "        }\n",
    "    ],\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643f1ca-6ed9-421f-98c9-a737c67e155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_run.status.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba0503-49a3-4be7-a1c2-f38d431450f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
