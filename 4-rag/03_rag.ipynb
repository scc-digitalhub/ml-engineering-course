{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07ef72e-40c1-4588-9632-0d4d20fb4424",
   "metadata": {},
   "source": [
    "# Rag application with LangChain\n",
    "\n",
    "This step will define the agent which connects the embedding model, the chat model and the vector store to fullfill the RAG scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a911fc47-d502-47f6-97c3-dfe826870927",
   "metadata": {},
   "source": [
    "## Project Initialization\n",
    "\n",
    "Initialize a DigitalHub project using consistent naming with other tutorials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338e311-4129-47ce-a59d-236eaac5e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "import getpass as gt\n",
    "\n",
    "USERNAME = gt.getuser()\n",
    "\n",
    "project = dh.get_or_create_project(f\"{USERNAME}-tutorial-project\")\n",
    "print(project.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887701b1-5e74-4526-94e1-444ca7e66ba8",
   "metadata": {},
   "source": [
    "## 1. Fetch components \n",
    "\n",
    "Let's get the components definition. We are looking for the latest RUNNING run for the 2 functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb27a78-7bd6-4c37-81b6-b3ac136e4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_function = project.get_function(\"embed\")\n",
    "embed_run = embed_function.list_runs()[0]\n",
    "if embed_run:\n",
    "    print(f\"Found run {embed_run.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4ea0e-037a-4995-bbd6-b653212cd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_function = project.get_function(\"llama32-1b\")\n",
    "llm_run = llm_function.list_runs()[0]\n",
    "if llm_run:\n",
    "    print(f\"Found run {llm_run.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd6950-ad57-4d5c-813c-ae200f111d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_URL = embed_run.status.to_dict()[\"service\"][\"url\"]\n",
    "EMBED_MODEL = embed_run.status.to_dict()[\"openai\"][\"model\"]\n",
    "print(f\"service {EMBED_URL} with model {EMBED_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f6e42-097c-4e53-9521-bf67c02e661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_URL = llm_run.status.to_dict()[\"service\"][\"url\"]\n",
    "CHAT_MODEL = llm_run.status.to_dict()[\"openai\"][\"model\"]\n",
    "print(f\"service {CHAT_URL} with model {CHAT_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800bc4bc-667c-4206-812a-c98adfc88fbc",
   "metadata": {},
   "source": [
    "## 2. Create the agent \n",
    "\n",
    "We'll register a python function implementing the RAG agent with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96635f88-c535-4e1a-964f-22a5f5665d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_func = project.new_function(\n",
    "    name=\"rag-service\", \n",
    "    kind=\"python\", \n",
    "    python_version=\"PYTHON3_10\", \n",
    "    image=\"harbor.digitalhub.smartcommunitylab.it/dslab/dslab-platform-harbor.atlas.fbk.eu/dslab/dslab-platform-msaloni-tutorial-project-rag-service:bc27b\",\n",
    "    code_src=\"src/serve.py\",     \n",
    "    handler=\"serve\",\n",
    "    init_function=\"init\",\n",
    "    requirements = [\n",
    "        \"transformers==4.50.3\",\n",
    "        \"psycopg[binary]==3.2.10\",\n",
    "        \"openai==1.109.1\",\n",
    "        \"langchain==0.3.27\",\n",
    "        \"langchain-core==0.3.76\",\n",
    "        \"langchain-openai==0.3.27\",\n",
    "        \"langchain-postgres==0.0.15\",\n",
    "        \"langchain-huggingface==0.3.1\",\n",
    "        \"langgraph==0.6.7\",\n",
    "        \"filelock==3.19.1\",\n",
    "        \"huggingface-hub==0.35.1\",\n",
    "        \"beautifulsoup4>=4.13.0\",\n",
    "        \"langchainhub==0.1.21\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8120c41-00a6-45f7-93c6-a47a072bcb35",
   "metadata": {},
   "source": [
    "And then we can run an instance connecting the model services together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f143f-1598-406a-907b-cb432f7b938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_run = serve_func.run(\n",
    "    action=\"serve\",\n",
    "    resources={\n",
    "        \"mem\":  \"8Gi\",\n",
    "    },\n",
    "    envs=[\n",
    "            {\"name\": \"CHAT_MODEL_NAME\", \"value\": CHAT_MODEL},\n",
    "            {\"name\": \"CHAT_SERVICE_URL\", \"value\": CHAT_URL},\n",
    "            {\"name\": \"EMBEDDING_MODEL_NAME\", \"value\": EMBED_MODEL},\n",
    "            {\"name\": \"EMBEDDING_SERVICE_URL\", \"value\": EMBED_URL}\n",
    "         ],\n",
    "    secrets=[\"PG_CONN_URL\"],\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb46eb7-f8e6-4459-a7a9-20299a44e6e8",
   "metadata": {},
   "source": [
    "If the execution fails, it is probably due to the large number of dependencies requirted. We need to build an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd5907-cec9-442c-a586-94fb0bb4531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serve_func.run(\"build\",wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f39f5-159b-4905-b94b-8f80bcf4f416",
   "metadata": {},
   "source": [
    "To test our API we make a call to the service endpoint providing a JSON with an example question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc077d-f15d-4467-b21b-040d41cd462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_URL = serve_run.status.to_dict()[\"service\"][\"url\"]\n",
    "print(AGENT_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e79958-0fbe-4f9d-aa7d-cb8c9e502ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "res = requests.post(f\"http://{AGENT_URL}\",json={\"question\": \"how can i use a personal access token DigitalHub console?\"})\n",
    "pp.pprint(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbcdaa-7bc5-453c-9e85-b3c1f6a3c0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
