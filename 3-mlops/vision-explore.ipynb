{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0818760a-5d1d-44c5-b049-10eaed7e9c87",
   "metadata": {},
   "source": [
    "# Exploration: training a model\n",
    "\n",
    "We create a pytorch-based model for image classification from public FashionMNIST dataset.\n",
    "\n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6508e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch==2.9.1 torchinfo==1.8.0 torchmetrics==1.8.2 torchvision==0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "dataset = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    # transform=ToTensor(),\n",
    ")\n",
    "\n",
    "labels = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a19de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    print(labels.get(dataset[i][1]))\n",
    "    display(dataset[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcb8b0",
   "metadata": {},
   "source": [
    "## A simple image classifier\n",
    "\n",
    "Let's train a network for classifiying images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83004f15-43bf-4565-bc77-c450fdd9cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network definition: how is it composed?\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "      super().__init__()\n",
    "      self.model = nn.Sequential(\n",
    "          nn.Conv2d(1, 8, kernel_size=3),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(8, 16, kernel_size=3),\n",
    "          nn.ReLU(),\n",
    "          nn.Flatten(),\n",
    "          nn.LazyLinear(10),  # 10 classes in total.\n",
    "      )\n",
    "\n",
    "  def forward(self, x):\n",
    "      return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7369ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the dataset in a compatible layout\n",
    "training_data = datasets.FashionMNIST(\n",
    "  root=\"data\",\n",
    "  train=True,\n",
    "  download=True,\n",
    "  transform=ToTensor(),\n",
    ")\n",
    "\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feeding the train loop we need a dataloader\n",
    "train_dataloader = DataLoader(training_data, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ImageClassifier().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da500ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the target metric and the optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are ready to train the model\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does it work? Let's try\n",
    "sample_input = training_data[0][0][None, :].numpy()      \n",
    "with torch.no_grad():\n",
    "    output = model(torch.tensor(sample_input))\n",
    "    sample_output = output.numpy()\n",
    "    print(sample_output)\n",
    "\n",
    "# what is the output?\n",
    "# what was the expected (true) value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3df119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we iterate over the dataset to train the network\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "  X = X.to(device)\n",
    "  y = y.to(device)\n",
    "\n",
    "  pred = model(X)\n",
    "  loss = loss_fn(pred, y)\n",
    "  \n",
    "  # Backpropagation.\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  if batch % 100 == 0:\n",
    "      loss_value = loss.item()\n",
    "      current = batch\n",
    "      step = batch // 100\n",
    "      print(f\"step {step} loss: {loss_value:2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0875116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a812a3a",
   "metadata": {},
   "source": [
    "the resulting model is structured as follows:\n",
    "```\n",
    "Input: Grayscale image (1xHxW)\n",
    "↓\n",
    "Conv2d(1→8, 3x3): Extracts 8 basic features (edges/textures)\n",
    "↓\n",
    "ReLU(): Adds non-linearity\n",
    "↓\n",
    "Conv2d(8→16, 3x3): Learns 16 complex features (patterns/shapes)\n",
    "↓\n",
    "ReLU(): Non-linearity\n",
    "↓\n",
    "Flatten(): Converts 16xHxW → 9216-dim vector (16 * 96 * 96 for 28x28 input)\n",
    "↓\n",
    "Linear(9216→10): Outputs class scores for 10 categories\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58cc2ff",
   "metadata": {},
   "source": [
    "## Evaluate results\n",
    "\n",
    "We can directly test the model against the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682005c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = training_data[0][0][None, :].numpy()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e6f0c-6da7-4e2a-ba19-e791da68ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get model output - convert tensor to numpy\n",
    "with torch.no_grad():\n",
    "    output = model(torch.tensor(sample_input))\n",
    "    sample_output = output.numpy()\n",
    "    print(sample_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d579f32",
   "metadata": {},
   "source": [
    "what is the output?\n",
    "What is the true value?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
