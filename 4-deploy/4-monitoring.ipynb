{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce85d43-22fa-4815-857d-7b122a6f3c8c",
   "metadata": {},
   "source": [
    "# Setup a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728446f3-91d8-409d-8f31-537d1cb05c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "project = dh.get_or_create_project(f\"{os.environ['USER']}-ml-service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b690cf0-4338-471e-80a8-3486cc06048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/monitor.py\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "BUCKET = \"datalake\"\n",
    "KEY = f\"{os.environ['PROJECT_NAME']}/monitordata.parquet\"\n",
    "\n",
    "def write_records(inputs,output):\n",
    "    s3 = boto3.client('s3')\n",
    "    d = {}\n",
    "    for i in inputs:\n",
    "        d[i['name']] = i['data']\n",
    "    d['predict']=output\n",
    "    ndf = pd.DataFrame(d)\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=KEY)\n",
    "        df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame()\n",
    "    \n",
    "    df = pd.concat([df,ndf])\n",
    "    df = df.tail(30000)\n",
    "    \n",
    "    df.to_parquet(\"monitoringdata.parquet\")\n",
    "    s3.upload_file(\"monitoringdata.parquet\", BUCKET, KEY)\n",
    "\n",
    "def init(context):\n",
    "    url = os.getenv(\"SERVICE_URL\")\n",
    "    if not url:\n",
    "        raise Exception(\"Missing SERVICE_URL env variable\")\n",
    "        \n",
    "    setattr(context, \"service\", url)\n",
    "\n",
    "def serve(context, event):\n",
    "    context.logger.info(f\"Received event: {event}\")\n",
    "    \n",
    "    if isinstance(event.body, bytes):\n",
    "        body = json.loads(event.body)\n",
    "    else:\n",
    "        body = event.body\n",
    "        \n",
    "    inputs = body[\"inputs\"]\n",
    "    res = requests.post(f\"http://{context.service}\", json=body)\n",
    "    output_json = json.loads(res.text)    \n",
    "\n",
    "    write_records(inputs, output_json['outputs'][0]['data'][0])\n",
    "     \n",
    "    return output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aefbbf-4039-41e9-a3ff-ebbfd88c298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = project.new_function(\n",
    "    name=\"monitor\", \n",
    "    kind=\"python\", \n",
    "    python_version=\"PYTHON3_10\", \n",
    "    code_src=\"src/monitor.py\",     \n",
    "    handler=\"serve\",\n",
    "    init_function=\"init\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c1d36-a54b-4da0-b3ac-a2b316b8cef9",
   "metadata": {},
   "source": [
    "Note the value of the SERVICE_URL property: it corresponds to the URL of the predictor service + '/v2/models/taxi-predictor/infer' endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9002a7-edf7-43ce-a7ed-bb3cdd4f5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_run = monitor.run(action=\"serve\", envs=[{\"name\": \"SERVICE_URL\", \"value\": \"s-mlflowserveserve-9ea298144e8e4aeba0ad18b5e4aff70c.dslab-platform:8080/v2/models/taxi-predictor/infer\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a14f71-33c7-4070-b700-75302bcb4f00",
   "metadata": {},
   "source": [
    "## Fill in the production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08246d66-2c61-46fc-a484-9ae797418c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feb_data = pd.read_parquet('data/green_tripdata_2022-02.parquet')\n",
    "feb_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d4876-13f8-4e5f-bee8-569cc2134dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_data = feb_data[1001:2000]\n",
    "num_features = [\"passenger_count\", \"trip_distance\", \"fare_amount\", \"total_amount\"]\n",
    "cat_features = [\"PULocationID\", \"DOLocationID\"]\n",
    "feb_data = feb_data[num_features + cat_features]\n",
    "recs = feb_data.to_dict(orient='records')\n",
    "inputs = []\n",
    "for r in recs:\n",
    "    inputs.append(\n",
    "    [{'name': 'passenger_count', 'shape': [1], 'datatype': 'FP32', 'data': [r['passenger_count']]},\n",
    "     {'name': 'trip_distance', 'shape': [1], 'datatype': 'FP32', 'data': [r['trip_distance']]},\n",
    "     {'name': 'fare_amount', 'shape': [1], 'datatype': 'FP32', 'data': [r['fare_amount']]},\n",
    "     {'name': 'total_amount', 'shape': [1], 'datatype': 'FP32', 'data': [r['total_amount']]},\n",
    "     {'name': 'PULocationID', 'shape': [1], 'datatype': 'UINT32', 'data': [r['PULocationID']]},\n",
    "     {'name': 'DOLocationID', 'shape': [1], 'datatype': 'UINT32', 'data': [r['DOLocationID']]}]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48096d7b-0ee8-4c84-86e4-d552a1196dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "for i in inputs:\n",
    "    inference_request = {\n",
    "        \"inputs\": i\n",
    "    }\n",
    "    \n",
    "    endpoint = f\"http://{monitor_run.refresh().status.service[\"url\"]}/v2/models/taxi-predictor/infer\"\n",
    "    response = requests.post(endpoint, json=inference_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40054011-7a1a-4101-a0f6-353c5b488a45",
   "metadata": {},
   "source": [
    "# Evaluate data drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b1be9-0da9-4b9b-b6da-9ceb004c0018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install evidently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afb209-13c2-4b9a-9f84-041673a9557c",
   "metadata": {},
   "source": [
    "### Define report model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25817b-af04-4c2d-b879-e33ffad86ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently import DataDefinition\n",
    "from evidently import Dataset\n",
    "from evidently import Report\n",
    "from evidently.metrics import ValueDrift, DriftedColumnsCount, MissingValueCount\n",
    "from evidently.presets import DataDriftPreset\n",
    "\n",
    "num_features = [\"passenger_count\", \"trip_distance\", \"fare_amount\", \"total_amount\"]\n",
    "cat_features = [\"PULocationID\", \"DOLocationID\"]\n",
    "\n",
    "data_definition = DataDefinition(numerical_columns=num_features + ['prediction'], categorical_columns=cat_features)\n",
    "\n",
    "report = Report(metrics=[\n",
    "    ValueDrift(column='prediction'),\n",
    "    DriftedColumnsCount(),\n",
    "    DataDriftPreset(),\n",
    "    MissingValueCount(column='prediction'),\n",
    "], include_tests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820ea17-3dad-4531-b692-0f28778054b6",
   "metadata": {},
   "source": [
    "### Recover reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87be95-3ee1-405a-98b5-797664f0a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "project.get_model(\"taxi-predictor\").download(overwrite=True)\n",
    "model = mlflow.pyfunc.load_model('./model/model/')\n",
    "df = project.get_dataitem('train-data').as_df()\n",
    "prediction = model.predict(df[num_features + cat_features])\n",
    "df['prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f2649-e57d-4321-a693-eaf1b4bf70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(\n",
    "    df,\n",
    "    data_definition\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f796577-5f2c-4fd6-af95-caa2ed28028e",
   "metadata": {},
   "source": [
    "### Recover current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d619e70-b98c-4416-8ca3-0969298e3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket='datalake', Key=f\"{os.environ['USER']}-ml-service/monitordata.parquet\")\n",
    "current_df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "current_df = current_df.rename(columns={'predict': 'prediction'})\n",
    "\n",
    "val_dataset = Dataset.from_pandas(\n",
    "    current_df,\n",
    "    data_definition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1ab11-20d1-45a7-815a-4d92c27d1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = report.run(reference_data=train_dataset, current_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ebee6-e934-4068-9afd-510e2334ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62580e-d710-442c-bdc9-c7c5d6c57a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (OltreAI)",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
